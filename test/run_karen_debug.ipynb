{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: enumerative pose estimation\n",
    "# 1) Just enumerate over all rotations and see fit\n",
    "# 2) Record time and accuracy\n",
    "\n",
    "# TODO 2: template-driven pose (rotation) estim experiment on single frame\n",
    "# 1) Identify broad \"(any) object\" template (i.e. bounding box)\n",
    "# 2) Quickly estimate object axis alignment from templates within bounding box (e.g. corner-to-corner distance/angle)\n",
    "    # for the square example, easy corner detection is finding top/bottom x,y coords where color exists; from there can do simple geometric calcs\n",
    "# 3) enumerate over the top n (small number n compared to all enums) poses close to the alignment calculated in Step 2 \n",
    "    # this is roughly analogous to a proposal distributio\n",
    "# 4) Record time and accuracy, especially compared to the naive enumerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax3dp3.model import make_scoring_function\n",
    "from jax3dp3.rendering import render_cloud_at_pose, render_planes\n",
    "from jax3dp3.utils import make_centered_grid_enumeration_3d_points, make_cube_point_cloud, quaternion_to_rotation_matrix\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import genjax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Establish gt poses (6 planes of a cube)\n",
    "from jax3dp3.shape import get_cube_shape\n",
    "\n",
    "h, w, fx_fy, cx_cy = (\n",
    "    300,\n",
    "    300,\n",
    "    jnp.array([200.0, 200.0]),\n",
    "    jnp.array([150.0, 150.0]),\n",
    ")\n",
    "r = 0.1\n",
    "outlier_prob = 0.01\n",
    "pixel_smudge = 0\n",
    "\n",
    "num_frames = 50\n",
    "\n",
    "gt_poses = [\n",
    "    jnp.array([\n",
    "    [1.0, 0.0, 0.0, -1.0],   \n",
    "    [0.0, 1.0, 0.0, -1.0],   \n",
    "    [0.0, 0.0, 1.0, 2.0],   \n",
    "    [0.0, 0.0, 0.0, 1.0],   \n",
    "    ]\n",
    ")\n",
    "]\n",
    "rot = R.from_euler('zyx', [1.0, -0.1, -2.0], degrees=True).as_matrix()\n",
    "delta_pose =     jnp.array([\n",
    "    [1.0, 0.0, 0.0, 0.09],   \n",
    "    [0.0, 1.0, 0.0, 0.05],   \n",
    "    [0.0, 0.0, 1.0, 0.02],   \n",
    "    [0.0, 0.0, 0.0, 1.0],   \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 18:23:31.356594: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: cublas error\n",
      "2022-10-16 18:23:31.356633: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-10-16 18:23:31.357933: E external/org_tensorflow/tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (external/org_tensorflow/tensorflow/compiler/xla/service/gpu/gemm_algorithm_picker.cc:309) stream->parent()->GetBlasGemmAlgorithms(stream, &algorithms) \n",
      "*** Begin stack trace ***\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t_PyObject_MakeTpCall\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\tPyObject_Call\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\tPyObject_Call\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\tPyObject_Call\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\tPyObject_Call\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t_PyObject_MakeTpCall\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\tPyEval_EvalCode\n",
      "\t\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\tPyObject_Call\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\tPyEval_EvalCode\n",
      "\t\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t_PyFunction_Vectorcall\n",
      "\t\n",
      "\tPy_RunMain\n",
      "\tPy_BytesMain\n",
      "\t__libc_start_main\n",
      "\t\n",
      "*** End stack trace ***\n",
      "\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "INTERNAL: RET_CHECK failure (external/org_tensorflow/tensorflow/compiler/xla/service/gpu/gemm_algorithm_picker.cc:309) stream->parent()->GetBlasGemmAlgorithms(stream, &algorithms) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m delta_pose \u001b[39m=\u001b[39m delta_pose\u001b[39m.\u001b[39mat[:\u001b[39m3\u001b[39m,:\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mset(jnp\u001b[39m.\u001b[39marray(rot))\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_frames):\n\u001b[0;32m----> 4\u001b[0m     gt_poses\u001b[39m.\u001b[39mappend(gt_poses[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mdot(delta_pose))\n\u001b[1;32m      5\u001b[0m gt_poses \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mstack(gt_poses)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mgt_poses.shape\u001b[39m\u001b[39m\"\u001b[39m, gt_poses\u001b[39m.\u001b[39mshape)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/inversegraphics/lib/python3.10/site-packages/jax/_src/dispatch.py:994\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options, host_callbacks)\u001b[0m\n\u001b[1;32m    989\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    990\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[1;32m    991\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 994\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: INTERNAL: RET_CHECK failure (external/org_tensorflow/tensorflow/compiler/xla/service/gpu/gemm_algorithm_picker.cc:309) stream->parent()->GetBlasGemmAlgorithms(stream, &algorithms) "
     ]
    }
   ],
   "source": [
    "delta_pose = delta_pose.at[:3,:3].set(jnp.array(rot))\n",
    "\n",
    "for t in range(num_frames):\n",
    "    gt_poses.append(gt_poses[-1].dot(delta_pose))\n",
    "gt_poses = jnp.stack(gt_poses)\n",
    "print(\"gt_poses.shape\", gt_poses.shape)\n",
    "\n",
    "shape = get_cube_shape(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 120, 160, 4)\n",
      "1992\n",
      "1992\n"
     ]
    }
   ],
   "source": [
    "# render GT images from gt poses\n",
    "\n",
    "def render_planes_lambda(pose, shape):\n",
    "    return render_planes(pose, shape, h, w, fx_fy, cx_cy)\n",
    "\n",
    "\n",
    "render_planes_lambda_jit = jax.jit(render_planes_lambda)\n",
    "\n",
    "key = jax.random.PRNGKey(3)\n",
    "\n",
    "gt_images = jnp.stack([render_planes_lambda_jit(p, shape) for p in gt_poses])\n",
    "print(gt_images.shape)\n",
    "print((gt_images[0, :, :, -1] > 0).sum()); print((gt_images[0, :, :, 0] != 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "testframe = 10\n",
    "nonzero_h, nonzero_w = jnp.nonzero(jnp.any(gt_images[testframe][:,:], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalleps = 1e-3\n",
    "topleft = gt_images[testframe, nonzero_h[0], nonzero_w[0]]\n",
    "bottomright = gt_images[testframe, nonzero_h[-1], nonzero_w[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# visulaize the frame\u001b[39;00m\n\u001b[1;32m      2\u001b[0m middle_width \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[0;32m----> 4\u001b[0m temp_viz \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mnew(\n\u001b[1;32m      5\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m, (gt_images\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m middle_width, gt_images\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m temp_viz\u001b[39m.\u001b[39mpaste(\n\u001b[1;32m      8\u001b[0m     Image\u001b[39m.\u001b[39mfromarray(\n\u001b[1;32m      9\u001b[0m         np\u001b[39m.\u001b[39marray(gt_images[testframe, :, :, \u001b[39m2\u001b[39m]) \u001b[39m/\u001b[39m \u001b[39m10.0\u001b[39m \u001b[39m*\u001b[39m \u001b[39m255.0\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m     ),\n\u001b[1;32m     11\u001b[0m     (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m),\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m temp_viz\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "# visulaize the frame\n",
    "middle_width = 20\n",
    "\n",
    "temp_viz = Image.new(\n",
    "        \"RGB\", (gt_images.shape[2] + middle_width, gt_images.shape[1])\n",
    ")\n",
    "temp_viz.paste(\n",
    "    Image.fromarray(\n",
    "        np.array(gt_images[testframe, :, :, 2]) / 10.0 * 255.0, mode=\"F\"\n",
    "    ),\n",
    "    (0, 0),\n",
    ")\n",
    "temp_viz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cube corner stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "cube_corner_plane_poses = jnp.array(\n",
    "    [\n",
    "        [\n",
    "            [1.0, 0.0, 0.0, 0.0],\n",
    "            [0.0, 1.0, 0.0, 0.0],\n",
    "            [0.0, 0.0, 1.0, 0.5],\n",
    "            [0.0, 0.0, 0.0, 1.0],\n",
    "        ], # back\n",
    "        # [\n",
    "        #     [1.0, 0.0, 0.0, 0.0],\n",
    "        #     [0.0, 1.0, 0.0, 0.0],\n",
    "        #     [0.0, 0.0, 1.0, -0.5],\n",
    "        #     [0.0, 0.0, 0.0, 1.0],\n",
    "        # ], # front\n",
    "        # [\n",
    "        #     [1.0, 0.0, 0.0, 0.0],\n",
    "        #     [0.0, 0.0, -1.0, 0.5],\n",
    "        #     [0.0, 1.0, 0.0, 0.0],\n",
    "        #     [0.0, 0.0, 0.0, 1.0],\n",
    "        # ], # bottom\n",
    "        [\n",
    "            [1.0, 0.0, 0.0, 0.0],\n",
    "            [0.0, 0.0, -1.0, -0.5],\n",
    "            [0.0, 1.0, 0.0, 0.0],\n",
    "            [0.0, 0.0, 0.0, 1.0],\n",
    "        ],\n",
    "        # [\n",
    "        #     [0.0, 0.0, 1.0, 0.5],\n",
    "        #     [0.0, 1.0, 0.0, 0.0],\n",
    "        #     [-1.0, 0.0, 0.0, 0.0],\n",
    "        #     [0.0, 0.0, 0.0, 1.0],\n",
    "        # ],\n",
    "        [\n",
    "            [0.0, 0.0, 1.0, -0.5],\n",
    "            [0.0, 1.0, 0.0, 0.0],\n",
    "            [-1.0, 0.0, 0.0, 0.0],\n",
    "            [0.0, 0.0, 0.0, 1.0],\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "corner_plane_dimensions = jnp.array(\n",
    "    [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]#, [0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n",
    ") \n",
    "corner_shape = (cube_corner_plane_poses, corner_plane_dimensions)\n",
    "print(cube_corner_plane_poses.shape)\n",
    "\n",
    "corner_image = render_planes_lambda_jit(gt_poses[10], corner_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAAB4CAIAAAD6wG44AAACkklEQVR4nO3az6riMBTH8UQGN27cuPJpRBFBEREU8QEVhCKK7nwyXWQWZUqnadM4Ojc96fezuOSe/rm5/jitKVUKAAAAAAAAAAAAAAAAAAAAAAAAAIACHXoCjXC9Xo0xxhilVH5Q+HW73Yad5z/4FXoC/9H9fveJzRjzfD4du3W7XWOM1iKbIcKAL5eLI7ZCfo5ir9fLxlrrdCxOJAEnSaL+ZJPPVb0ZqlKq3+8XcpWbrpIe8Ol0SqN6vV6e+VX9HAwG2YGluQq9RMub9PF49E+xdofhcFi6f9XZNpvNj//HHxHWwYfDQSnV6XR0BXtTWlHOFLNmLQwiaOJO6Al8kx1AvpKN7YFPXWK6KpqA02a1i/a4alBbF0pYwPv93i76Z9DCJhYWsK3qQ3c0dKuaWGrA2Xeoqq32zoVNnk1ctZsU8gJ25OpzrHtQm7o48gKuVXtbbVUTxxZwbee1rYmjCtidwVfuxOLEE7DnOli1rInlBbzb7eyi50fv08SRLZbkBWwr/ejtlv3KY0txZAdctWRypPJhE5/P5+9M/acIDtj/suwex93EIgN2P+uofbzVqjuxyIAd3loHt6GJowq4tq1LA3u3iWURGXDp+8nudXBp3dHEcaSrhAbswyddd7G0Li7mSAKufUjpGMTdxMJeurOVfqMuTWI0GtnFx+ORHVJ4785dl0J2wD4tpbUej8dVWyeTSe0ZbrdbPua3Zhic1IAdS+F8fTqdfv63FovF5ycJRWrAVbJ0Z7NZ2Jk0hLALTl6SJPpv6Tvu8/k89NQaJJ4OXi6XoafQRDEEvFqtQk+huWQHvF6vQ08BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAqd+ZuoMIf2s4BwAAAABJRU5ErkJggg=="
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "corner_viz = Image.new(\n",
    "        \"RGB\", (corner_image.shape[1], corner_image.shape[0])\n",
    ")\n",
    "corner_viz.paste(\n",
    "    Image.fromarray(\n",
    "        np.array(corner_image[:, :, 2]) / 10.0 * 255.0, mode=\"F\"\n",
    "    ),\n",
    "    (0, 0),\n",
    ")\n",
    "corner_viz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "import numpy as np\n",
    "\n",
    "imggray = gt_images[testframe, :, :, 2] / 10.0 * 255.0\n",
    "\n",
    "@jax.jit\n",
    "def gradient_x(imggray):\n",
    "    ##Sobel operator kernels.\n",
    "    kernel_x = jnp.array([[-1, 0, 1],[-2, 0, 2],[-1, 0, 1]])\n",
    "    return jax.scipy.signal.convolve2d(imggray, kernel_x, mode='same')\n",
    "\n",
    "@jax.jit\n",
    "def gradient_y(imggray):\n",
    "    kernel_y = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "    return jax.scipy.signal.convolve2d(imggray, kernel_y, mode='same')\n",
    "\n",
    "I_x = gradient_x(imggray)\n",
    "I_y = gradient_y(imggray) \n",
    "\n",
    "Ixx = ndi.gaussian_filter(I_x**2, sigma=1)\n",
    "Ixy = ndi.gaussian_filter(I_y*I_x, sigma=1)\n",
    "Iyy = ndi.gaussian_filter(I_y**2, sigma=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.06\n",
    "\n",
    "# determinant\n",
    "detA = Ixx * Iyy - Ixy ** 2\n",
    "# trace\n",
    "traceA = Ixx + Iyy\n",
    "    \n",
    "harris_response = detA - k * traceA ** 2  # compute harris response in det-trace space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">399</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m399\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smalleps = 1e-3\n",
    "rr, cr = range(h), range(w)\n",
    "\n",
    "from PIL import ImageDraw\n",
    "draw = ImageDraw.Draw(temp_viz)\n",
    "\n",
    "cnt = 0\n",
    "x = []\n",
    "max_sofar = float('-inf')\n",
    "# jax todo: practice optimizing this\n",
    "for rowindex, response in enumerate(harris_response):\n",
    "    for colindex, r in enumerate(response):\n",
    "        if r > 0:\n",
    "            cnt += 1\n",
    "            if r > max_sofar:\n",
    "                max_sofar = r\n",
    "                max_r, max_c = rowindex, colindex\n",
    "                draw.ellipse([max_c-smalleps, max_r-smalleps, \n",
    "                    max_c + smalleps, max_r + smalleps], fill='red')\n",
    "            # this is a corner\n",
    "            # draw.ellipse([colindex-smalleps, rowindex-smalleps, \n",
    "            #             colindex + smalleps, rowindex + smalleps], fill='blue')\n",
    "            temp_viz\n",
    "draw.ellipse([max_c-smalleps, max_r-smalleps, \n",
    "            max_c + smalleps, max_r + smalleps], fill='red')\n",
    "\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinate image template and do 2d icp\n",
    "\n",
    "# ICP on 2d patch? \n",
    "\n",
    "# at each pixel compute distances to all neighbors, take argmin, then store 3d coordinate of the argmin neighbor\n",
    "# and ultimately get NN of each point\n",
    "# will be fast because no kdtree yay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render GT images from gt poses\n",
    "\n",
    "def render_planes_lambda(pose, shape):\n",
    "    return render_planes(pose, shape, h, w, fx_fy, cx_cy)\n",
    "\n",
    "\n",
    "render_planes_lambda_jit = jax.jit(render_planes_lambda)\n",
    "\n",
    "key = jax.random.PRNGKey(3)\n",
    "\n",
    "gt_images = jnp.stack([render_planes_lambda_jit(p, shape) for p in gt_poses])\n",
    "print(gt_images.shape)\n",
    "print((gt_images[0, :, :, -1] > 0).sum()); print((gt_images[0, :, :, 0] != 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scorer \n",
    "scorer = make_scoring_function(shape, h, w, fx_fy, cx_cy, r, outlier_prob)\n",
    "score = scorer(key, gt_poses[0], gt_images[0, :, :, :])\n",
    "\n",
    "scorer_parallel = jax.vmap(scorer, in_axes=(0, 0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pose deltas to be used for proposals\n",
    "\n",
    "key, *sub_keys = jax.random.split(key, 15)\n",
    "\n",
    "def f(key):\n",
    "    key, (_, v) = genjax.VonMisesFisher.random_weighted(\n",
    "        key, jnp.array([1.0, 0.0, 0.0, 0.0]), float('inf')  # rand sample rotation\n",
    "    )\n",
    "    return quaternion_to_rotation_matrix(v)\n",
    "\n",
    "rotation_deltas = [f(sub_key) for sub_key in sub_keys]\n",
    "grid = make_centered_grid_enumeration_3d_points(0.2, 0.2, 0.2, 4, 4, 4)\n",
    "pose_deltas = [\n",
    "    jnp.vstack(\n",
    "        [jnp.hstack([R, t.reshape(3, 1)]), jnp.array([0.0, 0.0, 0.0, 1.0])]\n",
    "    )\n",
    "    for R in rotation_deltas\n",
    "    for t in grid\n",
    "]\n",
    "\n",
    "\n",
    "pose_deltas = jnp.stack(pose_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid  (896, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"grid \", pose_deltas.shape)\n",
    "key, *sub_keys = jax.random.split(key, pose_deltas.shape[0] + 1)\n",
    "sub_keys = jnp.array(sub_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _inner(x, gt_image):\n",
    "    for _ in range(1):\n",
    "        proposals = jnp.einsum(\"ij,ajk->aik\", x, pose_deltas)  # proposed poses by applying pose deltas\n",
    "        _, weights_new, x = scorer_parallel(sub_keys, proposals, gt_image)\n",
    "        x = proposals[jnp.argmax(weights_new)]  # return highest pose proposal\n",
    "    return x, x\n",
    "\n",
    "\n",
    "def inference(init_pos, gt_images):\n",
    "    return jax.lax.scan(_inner, init_pos, gt_images)\n",
    "\n",
    "\n",
    "inference_jit = jax.jit(inference)\n",
    "a = inference_jit(gt_poses[0], gt_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 3.7326395511627197\n",
      "FPS: 13.663253389712775\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "_, inferred_poses = inference_jit(gt_poses[0], gt_images)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Time elapsed:\", elapsed)\n",
    "print(\"FPS:\", gt_images.shape[0] / elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "middle_width = 20\n",
    "for i in range(gt_images.shape[0]):\n",
    "    dst = Image.new(\n",
    "        \"RGB\", (2 * gt_images.shape[2] + middle_width, gt_images.shape[1])\n",
    "    )\n",
    "    dst.paste(\n",
    "        Image.fromarray(\n",
    "            np.array(gt_images[i, :, :, 2]) / 10.0 * 255.0, mode=\"F\"\n",
    "        ),\n",
    "        (0, 0),\n",
    "    )\n",
    "\n",
    "    dst.paste(\n",
    "        Image.new(\"RGB\", (middle_width, gt_images.shape[1]), (255, 255, 255)),\n",
    "        (gt_images.shape[2], 0),\n",
    "    )\n",
    "\n",
    "    pose = inferred_poses[i]\n",
    "    rendered_image = render_planes_lambda_jit(pose, shape)\n",
    "    dst.paste(\n",
    "        Image.fromarray(\n",
    "            np.array(rendered_image[:, :, 2]) / 10.0 * 255.0, mode=\"F\"\n",
    "        ),\n",
    "        (gt_images.shape[2] + middle_width, 0),\n",
    "    )\n",
    "    images.append(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].save(\n",
    "    fp=\"out_kerm.gif\",\n",
    "    format=\"GIF\",\n",
    "    append_images=images,\n",
    "    save_all=True,\n",
    "    duration=100,\n",
    "    loop=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ff7bd74eea0069c3d2b20ef09d68fdaa22e7d14984ec0911bc9944f0de1f581"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
