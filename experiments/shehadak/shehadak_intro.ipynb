{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from jax3dp3.viz.img import save_depth_image\n",
    "from jax3dp3.utils import depth_to_coords_in_camera\n",
    "\n",
    "from jax3dp3.shape import (\n",
    "    get_rectangular_prism_shape,\n",
    "    get_cube_shape,\n",
    ")\n",
    "\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metadata\n",
    "\n",
    "num_frames = 103\n",
    "data_path = \"data/videos\"\n",
    "\n",
    "width =  300\n",
    "height =  300\n",
    "fx =  150\n",
    "fy =  150\n",
    "cx =  150\n",
    "cy =  150\n",
    "\n",
    "fx_fy = jnp.array([fx, fy])\n",
    "cx_cy = jnp.array([cx, cy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and pre-process rgb and depth images\n",
    "\n",
    "rgb_images, depth_images = [], []\n",
    "rgb_images_pil = []\n",
    "for i in range(num_frames):\n",
    "    rgb_path = os.path.join(data_path, f\"frames/frame_{i}.jpeg\")\n",
    "    rgb_img = Image.open(rgb_path)\n",
    "    rgb_images_pil.append(rgb_img)\n",
    "    rgb_images.append(np.array(rgb_img))\n",
    "\n",
    "    depth_path = os.path.join(data_path, f\"depths/frame_{i}.npy\")\n",
    "    depth_npy = np.load(depth_path)\n",
    "    depth_images.append(depth_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_images_pil[0].save(\"rgb.png\")\n",
    "save_depth_image(depth_images[0], 30.0, \"depth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get masked objects based on the depth images\n",
    "\n",
    "img_idx = 50\n",
    "k = 5 if 5 <= img_idx < 19 else 4 # 4 objects in frames [5:19]\n",
    "\n",
    "K = jnp.array([\n",
    "    [fx_fy[0], 0.0, cx_cy[0]],\n",
    "    [0.0, fx_fy[1], cx_cy[1]],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])\n",
    "coord_image,_ = depth_to_coords_in_camera(depth_images[img_idx], K)\n",
    "print(coord_image.shape)\n",
    "# -.5 < x < 1\n",
    "# -.5 < y < .5\n",
    "# 1.2 < z < 4\n",
    "mask = np.invert(\n",
    "    (coord_image[:,:,0] < 1.0) *\n",
    "    (coord_image[:,:,0] > -0.5) *\n",
    "    (coord_image[:,:,1] < 0.28) *\n",
    "    (coord_image[:,:,1] > -0.5) *\n",
    "    (coord_image[:,:,2] < 4.0) *\n",
    "    (coord_image[:,:,2] > 1.2) \n",
    ")\n",
    "coord_image[mask,:] = 0.0\n",
    "save_depth_image(coord_image[:,:,2], 30.0, \"coord_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do K-Means clustering to segment objects from masked depth (i.e. entity extraction)\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, .02)\n",
    "\n",
    "coord_image_flat = coord_image.reshape(-1, 3).astype(dtype=np.float32)\n",
    "_, labels, centers = cv2.kmeans(coord_image_flat, k, None, criteria, 10, cv2.KMEANS_PP_CENTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "_a = labels.reshape(300, 300)\n",
    "_img = np.stack((_a, _a, _a), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    _img[_a == i] = np.array([250, 250, 250])\n",
    "    _img[_a != i] = np.array([0, 0, 0])\n",
    "    PIL_image = Image.fromarray(np.uint8(_img)).convert('RGB')\n",
    "    PIL_image.save(f\"pil_{i}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_images.shape (104, 300, 300, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAYAAAB5fY51AAAEH0lEQVR4nO3XoQ3CUBhG0ZYwADAIaYLsPmhGYTFmwWEQZYUa0tz0HP3Ep27+N06XeRkAAg5bDwBYS7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIOO49QBazrfHqnfv1/OvO9gnwWK10/U+LN/P1jPYMV9CIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CADMECMgQLyBAsIEOwgAzBAjIEC8gQLCBDsIAMwQIyBAvIECwgQ7CAjHG6zMvWIwDWcGEBGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARmCBWQIFpAhWECGYAEZggVkCBaQIVhAhmABGYIFZAgWkCFYQIZgARk//P8L52dQJMYAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=300x300>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from jax3dp3.rendering import render_planes\n",
    "\n",
    "cup_shape = get_rectangular_prism_shape([0.075, 0.15, 0.075])\n",
    "reward_shape = get_cube_shape(0.08)\n",
    "\n",
    "shape = cup_shape\n",
    "\n",
    "gt_poses = [\n",
    "    jnp.array([\n",
    "    [1.0, 0.0, 0.0, -.35],   \n",
    "    [0.0, 1.0, 0.0, .17],   \n",
    "    [0.0, 0.0, 1.0, 2.0],   \n",
    "    [0.0, 0.0, 0.0, 1.0],   \n",
    "    ]\n",
    ")\n",
    "]\n",
    "rot = R.from_euler('zyx', [0, 0, 0], degrees=True).as_matrix()\n",
    "delta_pose = jnp.array([\n",
    "    [1.0, 0.0, 0.0, 0.09],   \n",
    "    [0.0, 1.0, 0.0, 0.05],   \n",
    "    [0.0, 0.0, 1.0, 0.02],   \n",
    "    [0.0, 0.0, 0.0, 1.0],   \n",
    "    ]\n",
    ")\n",
    "delta_pose = delta_pose.at[:3,:3].set(jnp.array(rot))\n",
    "\n",
    "for t in range(num_frames):\n",
    "    gt_poses.append(gt_poses[-1].dot(delta_pose))\n",
    "gt_poses = jnp.stack(gt_poses)\n",
    "\n",
    "render_planes_jit = jax.jit(lambda p: render_planes(p, shape, height, width, fx_fy,cx_cy))\n",
    "render_planes_parallel_jit = jax.jit(jax.vmap(lambda p: render_planes(p,shape,height,width,fx_fy,cx_cy)))\n",
    "gt_images = render_planes_parallel_jit(gt_poses)\n",
    "print(\"gt_images.shape\", gt_images.shape)\n",
    "\n",
    "cm = plt.get_cmap('turbo')\n",
    "\n",
    "obsedved_image_pil = Image.fromarray(\n",
    "        (cm(np.array(gt_images[i,:, :, 2]) / 30) * 255.0).astype(np.int8), mode=\"RGBA\"\n",
    "    )\n",
    "\n",
    "obsedved_image_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a3868bdd7d3c8a3e0bdbdcc5d56cecdac1cfc8e4c924f480e3352f5fc391e73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
