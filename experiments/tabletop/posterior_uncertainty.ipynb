{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15c8065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import bayes3d as j\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import os\n",
    "import trimesh\n",
    "import copy\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "intrinsics = j.Intrinsics(\n",
    "    height=100,\n",
    "    width=100,\n",
    "    fx=100.0, fy=100.0,\n",
    "    cx=50.0, cy=50.0,\n",
    "    near=1.0, far=500.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3034e99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7002/static/\n"
     ]
    }
   ],
   "source": [
    "j.setup_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02028196",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_params = (1000.0,\n",
    "    1000.0,\n",
    "    0.01,\n",
    "    0.01,\n",
    "    0.01)\n",
    "table_mesh = j.mesh.make_table_mesh(\n",
    "    *table_params\n",
    ")\n",
    "table_dims = j.utils.aabb(table_mesh.vertices)[0]\n",
    "table_pose = j.t3d.inverse_pose(\n",
    "    j.t3d.transform_from_pos_target_up(\n",
    "        jnp.array([0.0, 300.0, 150.0]),\n",
    "        jnp.array([0.0, 0.0, 0.0]),\n",
    "        jnp.array([0.0, 0.0, 1.0]),\n",
    "    )\n",
    ")\n",
    "contact_plane = table_pose @ j.scene_graph.get_contact_planes(table_dims)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b857fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E rasterize_gl.cpp:121] OpenGL version reported as 4.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing frame buffer size to (width, height, depth) = (128, 128, 1024)\n"
     ]
    }
   ],
   "source": [
    "occluder = j.mesh.make_cuboid_mesh(jnp.array([10.0, 70.0, 100.0]))                       \n",
    "obj_a = j.mesh.make_cuboid_mesh(jnp.array([50.0, 100.0, 50.0]))                       \n",
    "obj_b = j.mesh.make_cuboid_mesh(jnp.array([50.0, 60.0, 50.0]))\n",
    "obj_c = j.mesh.make_cuboid_mesh(jnp.array([50.0, 20.0, 50.0]))\n",
    "renderer = j.Renderer(intrinsics, num_layers=1024)\n",
    "renderer.add_mesh(occluder)\n",
    "renderer.add_mesh(obj_a)\n",
    "renderer.add_mesh(obj_b)\n",
    "renderer.add_mesh(obj_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef66ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79edc123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ec786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8138356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(object_poses, object_ids, r_array):\n",
    "    reconstruction = renderer.render_multiobject(\n",
    "        object_poses, object_ids\n",
    "    )\n",
    "    rendered_seg = reconstruction[:,:,3]\n",
    "    r = r_array[jnp.abs(rendered_seg[..., None] - jnp.arange(len(r_array))).argmin(-1)]\n",
    "    key = jax.random.PRNGKey(10)\n",
    "    noisy_point_cloud_image = jax.random.multivariate_normal(\n",
    "        key, reconstruction[:,:,:3], (jnp.eye(3)[None, None, :, :] * r[:,:,None,None]), shape=r.shape\n",
    "    )\n",
    "    img = j.render_point_cloud(noisy_point_cloud_image.reshape(-1,3), intrinsics)\n",
    "    return img\n",
    "\n",
    "def inference():\n",
    "    all_hypotheses = []\n",
    "    for obj_id in range(1,len(renderer.meshes)):\n",
    "#         print(\"Object ID \", obj_id)\n",
    "        contact_param = jnp.zeros(3)\n",
    "        p = None\n",
    "        traces = None\n",
    "        for c2f_iter in range(len(contact_param_gridding_schedule)):\n",
    "            contact_param_grid = contact_param_gridding_schedule[c2f_iter] + contact_param\n",
    "\n",
    "            potential_new_object_poses = contact_plane @ pose_from_contact_and_face_params_parallel_jit(\n",
    "                contact_param_grid,\n",
    "                3,\n",
    "                renderer.model_box_dims[obj_id],\n",
    "            )\n",
    "            POTENTIAL_R = jnp.hstack([jnp.tile(R[None,:], (R_SWEEP.shape[0], 1)),R_SWEEP])\n",
    "\n",
    "            potential_poses = jnp.concatenate(\n",
    "                [\n",
    "                    jnp.tile(object_poses, (1,potential_new_object_poses.shape[0],1,1)),\n",
    "                    potential_new_object_poses[None,...]\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            traces = j.Traces(\n",
    "                potential_poses, object_ids + [obj_id], POTENTIAL_R, OUTLIER_PROBS, OUTLIER_VOLUME, observed_point_cloud_image\n",
    "            )\n",
    "            p = j.score_traces(traces, renderer)\n",
    "            ii,jj,kk = jnp.unravel_index(p.argmax(), p.shape)\n",
    "            contact_param = contact_param_grid[ii]\n",
    "\n",
    "        all_hypotheses.append(\n",
    "            traces[ii,jj,kk]\n",
    "        )\n",
    "\n",
    "    return all_hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a551c793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100.]\n",
      " [ 50.]\n",
      " [ 10.]\n",
      " [  5.]]\n"
     ]
    }
   ],
   "source": [
    "sched = [(100.0, jnp.pi), (50.0, jnp.pi), (10.0, jnp.pi),\n",
    "         (5.0, jnp.pi/2),(5.0, jnp.pi/2),(5.0, jnp.pi/2),\n",
    "         (2.0, jnp.pi/2),(2.0, jnp.pi/2),(2.0, jnp.pi/2),\n",
    "         (1.0, jnp.pi/4),(1.0, jnp.pi/4),(1.0, jnp.pi/4),\n",
    "]\n",
    "\n",
    "contact_param_gridding_schedule = [\n",
    "    j.make_translation_grid_enumeration_3d(\n",
    "        -x, 0.0, -y,\n",
    "        x, 0.0, y,\n",
    "        13,1,3\n",
    "    )\n",
    "    for (x,y) in sched\n",
    "]\n",
    "\n",
    "pose_from_contact_and_face_params_parallel_jit = jax.jit(jax.vmap(\n",
    "    j.scene_graph.relative_pose_from_edge, in_axes=(0,None, None))\n",
    ")\n",
    "\n",
    "R_SWEEP = jnp.array([100.0, 50.0, 10.0, 5.0]).reshape(-1,1)\n",
    "print(R_SWEEP)\n",
    "OUTLIER_PROBS = jnp.linspace(0.01, 0.2, 4)\n",
    "OUTLIER_VOLUME = 100.0**3 * 0.01\n",
    "SCALING_FACTOR = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d6b2ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES   [-107797.39 -107797.42 -107810.22]\n",
      "NORMALIZED SCORES   [5.0677532e-01 4.9118349e-01 1.3602903e-06]\n",
      "[0 1 2]\n",
      "Best\n",
      "variance: [10. 10.  5.] outlier_prob: 0.20000000298023224 outlier_volume: 10000.0\n",
      " ids: [Array(0, dtype=int32), 1] poses: [[[ 5.9604645e-08  1.0000000e+00  2.5611371e-08  1.2805685e-06]\n",
      "  [ 4.4726557e-01  4.9569280e-08 -8.9453125e-01 -4.4784546e-03]\n",
      "  [-8.9453125e-01 -4.1863132e-08 -4.4726557e-01  2.2368359e+02]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00]]\n",
      "\n",
      " [[-8.3469786e-08 -1.0000000e+00 -1.4924444e-07  6.1156246e+01]\n",
      "  [-4.4726557e-01  1.1750575e-07 -8.9453125e-01 -2.2367760e+01]\n",
      "  [ 8.9453125e-01  9.8748039e-08 -4.4726557e-01  3.2431613e+02]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00]]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__str__ returned non-string (type NoneType)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m best_hypothesis \u001b[38;5;241m=\u001b[39m all_hypotheses[jnp\u001b[38;5;241m.\u001b[39margmax(scores)]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbest_hypothesis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m R \u001b[38;5;241m=\u001b[39m best_r\n\u001b[1;32m     36\u001b[0m object_poses \u001b[38;5;241m=\u001b[39m best_poses[:,\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: __str__ returned non-string (type NoneType)"
     ]
    }
   ],
   "source": [
    "object_indices = jnp.array([0,1])\n",
    "\n",
    "poses = contact_plane @ j.scene_graph.relative_pose_from_edge_parallel_jit(\n",
    "    jnp.array(\n",
    "        [\n",
    "            [0.0, 100.0, 0.0],\n",
    "            [-60.0, 0.0, 0.0],\n",
    "        ]\n",
    "    ),\n",
    "    jnp.array([3,3]),\n",
    "    renderer.model_box_dims[object_indices],\n",
    ")\n",
    "SCALING_FACTOR = 4\n",
    "observed_point_cloud_image = renderer.render_multiobject(poses, object_indices)\n",
    "j.show_cloud(\"obs\", observed_point_cloud_image[:,:,:3].reshape(-1,3) / 1000.0)\n",
    "j.scale_image(j.get_depth_image(observed_point_cloud_image[:,:,2]),SCALING_FACTOR)\n",
    "\n",
    "R = jnp.array([10.0, 10.0])\n",
    "object_poses, object_ids = poses[:1,:,:][None,...], [object_indices[0]]\n",
    "reconstruction = renderer.render_multiobject(\n",
    "    object_poses, object_ids\n",
    ")\n",
    "\n",
    "all_hypotheses = inference()\n",
    "\n",
    "scores = jnp.array([j.score_trace(t, renderer) for t in all_hypotheses])\n",
    "normalized_scores = j.utils.normalize_log_scores(scores)\n",
    "print(\"SCORES  \", scores)\n",
    "print(\"NORMALIZED SCORES  \", normalized_scores)\n",
    "print(jnp.argsort(-scores))\n",
    "best_hypothesis = all_hypotheses[jnp.argmax(scores)]\n",
    "print(\"Best\")\n",
    "print(best_hypothesis)\n",
    "\n",
    "R = best_r\n",
    "object_poses = best_poses[:,None,...]\n",
    "object_ids = object_ids + [obj_id]\n",
    "print(object_ids)\n",
    "\n",
    "\n",
    "\n",
    "# height_factor = outlier_prob_viz.height / observed_image_viz.height\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(7,4))\n",
    "color = np.array([229, 107, 111])/255.0\n",
    "plt.bar(\n",
    "    np.arange(len(normalized_scores)),\n",
    "    normalized_scores,\n",
    "    color=color\n",
    ")\n",
    "plt.xticks(np.arange(len(normalized_scores)), [\"{:d}\".format(i) for i in range(len(normalized_scores))],fontsize=15)\n",
    "plt.yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0],fontsize=15)\n",
    "plt.xlabel(\"Object ID\",fontsize=20)\n",
    "plt.ylabel(\"Probability\",fontsize=20)\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.tight_layout()\n",
    "img_buf = io.BytesIO()\n",
    "plt.savefig(img_buf, format='png')\n",
    "posterior_bar_chart = Image.open(img_buf)\n",
    "\n",
    "depth_viz = j.scale_image(j.get_depth_image(observed_point_cloud_image[:,:,2]), SCALING_FACTOR)\n",
    "\n",
    "height_factor = depth_viz.height / posterior_bar_chart.height\n",
    "\n",
    "\n",
    "viz1 = j.multi_panel(\n",
    "    [\n",
    "        depth_viz,\n",
    "        j.scale_image(j.get_depth_image(reconstruction[:,:,2]), SCALING_FACTOR),\n",
    "        j.scale_image(posterior_bar_chart, height_factor)\n",
    "    ],\n",
    "    labels=[\n",
    "        \"Observed Image\",\n",
    "        \"Reconstruction\",\n",
    "        \"Posterior on Object Type\",\n",
    "    ],\n",
    "    middle_width=30\n",
    ")\n",
    "\n",
    "viz2 = j.multi_panel(\n",
    "    [j.scale_image(j.get_depth_image(r[1][:,:,2]), SCALING_FACTOR) for r in all_hypotheses],\n",
    "    labels=[\"obj_{:d}\".format(idx, i.item()) for (idx,i) in enumerate(normalized_scores)],\n",
    "    title=\"Inferred Pose per Object Type\"\n",
    ")\n",
    "\n",
    "viz3 = j.multi_panel(\n",
    "    [j.scale_image(j.get_depth_image(sample_image(r[4][None,...], [object_indices[0],r[5]], r[2])[:,:,2]), SCALING_FACTOR) for r in all_hypotheses],\n",
    "    labels=[\"obj_{:d}, Noise: {:0.2f}\".format(idx, i[2][-1].item()) for (idx,i) in enumerate(all_hypotheses)],\n",
    "    title=\"Posterior Samples per Object Type\"\n",
    ")\n",
    "\n",
    "final_viz = j.vstack_images([viz1, viz2])\n",
    "final_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb2950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4f0af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "viz_images = []\n",
    "for block_x in jnp.linspace(-120.0, 120.0, 50):\n",
    "    print(\"x :\", block_x)\n",
    "    object_indices = jnp.array([0,1])\n",
    "\n",
    "    poses = contact_plane @ j.scene_graph.relative_pose_from_edge_parallel_jit(\n",
    "        jnp.array(\n",
    "            [\n",
    "                [0.0, 100.0, 0.0],\n",
    "                [block_x, 0.0, 0.0],\n",
    "            ]\n",
    "        ),\n",
    "        jnp.array([3,3]),\n",
    "        renderer.model_box_dims[object_indices],\n",
    "    )\n",
    "    SCALING_FACTOR = 4\n",
    "    observed_point_cloud_image = renderer.render_multiobject(poses, object_indices)\n",
    "    j.scale_image(j.get_depth_image(observed_point_cloud_image[:,:,2]),SCALING_FACTOR)\n",
    "\n",
    "\n",
    "    R = jnp.array([10.0, 1.0])\n",
    "    object_poses, object_ids = poses[:1,:,:][None,...], [object_indices[0]]\n",
    "    reconstruction = renderer.render_multiobject(\n",
    "        object_poses, object_ids\n",
    "    )\n",
    "\n",
    "    all_hypotheses = inference()\n",
    "\n",
    "\n",
    "    scores = jnp.array([i[0] for i in all_hypotheses])\n",
    "    normalized_scores = j.utils.normalize_log_scores(scores)\n",
    "    print(\"SCORES  \", scores)\n",
    "    print(\"NORMALIZED SCORES  \", normalized_scores)\n",
    "    print(jnp.argsort(-scores))\n",
    "    best_hypothesis = all_hypotheses[jnp.argmax(scores)]\n",
    "    score, reconstruction, best_r, best_outlier_prob, best_poses, obj_id = best_hypothesis\n",
    "    print(\"Best\")\n",
    "    print(best_r, best_outlier_prob, obj_id)\n",
    "\n",
    "    R = best_r\n",
    "    object_poses = best_poses[:,None,...]\n",
    "    object_ids = object_ids + [obj_id]\n",
    "    print(object_ids)\n",
    "\n",
    "    # outliers = (\n",
    "    #     (1.0 - best_outlier_prob) * (j.gaussian_mixture_image_multi_r_jit(observed_point_cloud_image, reconstruction[:,:,:3], reconstruction[:,:, -1], best_r))\n",
    "    #         <\n",
    "    #     (best_outlier_prob / OUTLIER_VOLUME)\n",
    "    # )\n",
    "\n",
    "    # height_factor = outlier_prob_viz.height / observed_image_viz.height\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(7,4))\n",
    "    color = np.array([229, 107, 111])/255.0\n",
    "    plt.bar(\n",
    "        np.arange(len(normalized_scores)),\n",
    "        normalized_scores,\n",
    "        color=color\n",
    "    )\n",
    "    plt.xticks(np.arange(len(normalized_scores)), [\"{:d}\".format(i) for i in range(len(normalized_scores))],fontsize=15)\n",
    "    plt.yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0],fontsize=15)\n",
    "    plt.xlabel(\"Object ID\",fontsize=20)\n",
    "    plt.ylabel(\"Probability\",fontsize=20)\n",
    "    plt.ylim(0.0, 1.05)\n",
    "    plt.tight_layout()\n",
    "    img_buf = io.BytesIO()\n",
    "    plt.savefig(img_buf, format='png')\n",
    "    posterior_bar_chart = Image.open(img_buf)\n",
    "\n",
    "    depth_viz = j.scale_image(j.get_depth_image(observed_point_cloud_image[:,:,2]), SCALING_FACTOR)\n",
    "\n",
    "    height_factor = depth_viz.height / posterior_bar_chart.height\n",
    "\n",
    "\n",
    "\n",
    "    # outlier_viz = j.scale_image(j.get_depth_image(1.0 - outliers), SCALING_FACTOR)\n",
    "    viz1 = j.multi_panel(\n",
    "        [\n",
    "            depth_viz,\n",
    "            j.scale_image(j.get_depth_image(reconstruction[:,:,2]), SCALING_FACTOR),\n",
    "            j.scale_image(posterior_bar_chart, height_factor)\n",
    "        ],\n",
    "        labels=[\n",
    "            \"Observed Image\",\n",
    "            \"Reconstruction\",\n",
    "            \"Posterior on Object Type\",\n",
    "        ],\n",
    "        middle_width=30\n",
    "    )\n",
    "\n",
    "    viz2 = j.multi_panel(\n",
    "        [j.scale_image(j.get_depth_image(r[1][:,:,2]), SCALING_FACTOR) for r in all_hypotheses],\n",
    "        labels=[\"obj_{:d}\".format(idx, i.item()) for (idx,i) in enumerate(normalized_scores)],\n",
    "        title=\"Inferred Pose per Object Type\"\n",
    "    )\n",
    "\n",
    "    final_viz = j.vstack_images([viz1, viz2])\n",
    "    viz_images.append(final_viz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a55423",
   "metadata": {},
   "outputs": [],
   "source": [
    "j.make_gif(viz_images, \"out.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970ac5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
