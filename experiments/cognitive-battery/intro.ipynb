{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cognitive Battery Introduction: Jax-3DP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import jax3dp3\n",
    "from jax3dp3.viz import (\n",
    "    get_depth_image,\n",
    "    multi_panel,\n",
    ")\n",
    "from jax3dp3.transforms_3d import transform_from_pos, unproject_depth\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax3dp3.viz import make_gif_from_pil_images\n",
    "from PIL import Image\n",
    "import trimesh\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cog_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = \"swap\"\n",
    "data_path = f\"/home/khaledshehada/cog_jax3dp3_data/{scene}_data/videos/\"\n",
    "num_frames = len(os.listdir(os.path.join(data_path, \"frames\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing frame buffer size to (width, height, depth) = (320, 320, 2048)\n"
     ]
    }
   ],
   "source": [
    "width = 300\n",
    "height = 300\n",
    "fov = 90\n",
    "\n",
    "fx, fy, cx, cy = utils.get_camera_intrinsics(width, height, fov)\n",
    "\n",
    "fx_fy = jnp.array([fx, fy])\n",
    "cx_cy = jnp.array([cx, cy])\n",
    "near, far = 0.001, 50.0\n",
    "K = jnp.array(\n",
    "    [\n",
    "        [fx_fy[0], 0.0, cx_cy[0]],\n",
    "        [0.0, fx_fy[1], cx_cy[1]],\n",
    "        [0.0, 0.0, 1.0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "jax3dp3.setup_renderer(height, width, fx, fy, cx, cy, near, far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_images, depth_images, seg_maps = [], [], []\n",
    "rgb_images_pil = []\n",
    "for i in range(num_frames):\n",
    "    rgb_path = os.path.join(data_path, f\"frames/frame_{i}.jpeg\")\n",
    "    if not os.path.isfile(rgb_path):\n",
    "        rgb_path = rgb_path.replace(\"jpeg\", \"png\")\n",
    "    rgb_img = Image.open(rgb_path)\n",
    "    rgb_images_pil.append(rgb_img)\n",
    "    rgb_images.append(np.array(rgb_img))\n",
    "\n",
    "    depth_path = os.path.join(data_path, f\"depths/frame_{i}.npy\")\n",
    "    depth_npy = np.load(depth_path)\n",
    "    depth_images.append(depth_npy)\n",
    "\n",
    "    seg_map = np.load(os.path.join(data_path, f\"segmented/frame_{i}.npy\"))\n",
    "    seg_maps.append(seg_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_images = []  # depth data in 2d view as images\n",
    "seg_images = []  # segmentation data as images\n",
    "\n",
    "for frame_idx in range(num_frames):\n",
    "    coord_image, _ = depth_to_coords_in_camera(depth_images[frame_idx], K)\n",
    "    segmentation_image = seg_maps[frame_idx].copy()\n",
    "    mask = np.invert(\n",
    "        (coord_image[:, :, 0] < 2.0)\n",
    "        * (coord_image[:, :, 0] > -1)\n",
    "        * (coord_image[:, :, 1] < 0.463)\n",
    "        * (coord_image[:, :, 1] > -0.8)\n",
    "        * (coord_image[:, :, 2] < 1.8)\n",
    "        * (coord_image[:, :, 2] > 0.25)\n",
    "    )\n",
    "    coord_image[mask, :] = 0.0\n",
    "    segmentation_image[mask, :] = 0.0\n",
    "    coord_images.append(coord_image)\n",
    "    seg_images.append(segmentation_image)\n",
    "\n",
    "coord_images = np.stack(coord_images)\n",
    "seg_images = np.stack(seg_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "mug\n"
     ]
    }
   ],
   "source": [
    "# Load meshes\n",
    "meshes = []\n",
    "meshes_path = data_path.replace(\"videos\", \"meshes\")\n",
    "for mesh_name in os.listdir(meshes_path):\n",
    "    if not mesh_name.endswith(\".obj\"): continue\n",
    "    mesh_path = os.path.join(meshes_path, mesh_name)\n",
    "    mesh = trimesh.load(mesh_path, force=\"mesh\")\n",
    "    jax3dp3.load_model(mesh)\n",
    "    meshes.append(mesh_name.replace(\".obj\", \"\"))\n",
    "    print(meshes[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAAC+UlEQVR4nO3dsWoUURSA4U0I2FpKOl8ghYX4HoJtwCYgIsRaK60NiAg2Qloh7yEWFnkBu2BpK4hYDCwys3PuzN3E4539vnbPwDQ/Z5s9u1oBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADADdvLfgHYyr1fT8Y++nrw/l++SbX97BeAekGBDREhi9VKoiJksXwdBSYRIQ1rZdfFRMgyNdSnCGnbxtgaKnAlQhagreQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAuDF72S9wnU4vP8QDZ0cn8cCDw9fxwOerF/HA24tP8cCzh4/igf3L+/HA76Mvwac/f3yMH791+3E8cHr+Kh44O34ZD9z9/iYe+HbneTxw/u4wHjh+ehUPNKTtCIvVDfU6LFa3US/FYnhDvRSL4Q0NUyzmN9QLspjfUC/IYn4b9ZosFjjUdJMH2S9Qo6K9obr8eiryG6oosHvq7w4rCuyeKi7GWNdtcTfGunSL6zGw7rbFGtv7k9BrKZClqtii6dqLEBZGhJBMhJBMhJBMhJBMhJBMhJBMhJBMhJBMhJBMhJBMhJBMhJBMhJBMhJBMhJBstyIs3piZonhmZpdt8+v4tRZ/Hb+NHYrw/ymwd2AmPtw0pvdU3ZWK3lNbXqno6HCuJg89zbpwMdbe3BszY/nNOjMTnFqbdWlmrNtZl2aCbmddfBpLd+7Rp7F6Z12saLHeJiNclTqcvvTiFKfvvTjF4pnDtTjF6TszrnH62oxrnL454yCnL884yBYLBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWJI/b46dZxr3XCcAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=300x300 at 0x7FC291B57090>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_t = 11\n",
    "seg_img = seg_images[start_t]\n",
    "\n",
    "Image.fromarray(seg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=300x300 at 0x7FC291A61E90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_objects = 10\n",
    "indices, init_poses = [], []\n",
    "obj_ids = jnp.unique(seg_img.reshape(-1, 3), axis=0)\n",
    "obj_ids = sorted(\n",
    "    obj_ids, key=lambda x: jnp.all(seg_img == x, axis=-1).sum(), reverse=True\n",
    ")\n",
    "for obj_id in obj_ids[: num_objects + 1]:\n",
    "    if jnp.all(obj_id == 0):\n",
    "        # Background\n",
    "        continue\n",
    "\n",
    "    obj_mask = jnp.all(seg_img == obj_id, axis=-1)\n",
    "    masked_depth = coord_images[start_t].copy()\n",
    "    masked_depth[~obj_mask] = 0\n",
    "\n",
    "    object_points = coord_images[start_t][obj_mask]\n",
    "    maxs = np.max(object_points, axis=0)\n",
    "    mins = np.min(object_points, axis=0)\n",
    "    dims = maxs - mins\n",
    "    obj_center = (maxs + mins) / 2\n",
    "    obj_transform = transform_from_pos(obj_center)\n",
    "\n",
    "    best = utils.find_best_mesh(meshes, obj_transform, masked_depth)\n",
    "    if best:\n",
    "        indices.append(best[0])\n",
    "        init_poses.append(best[1])\n",
    "\n",
    "init_poses = jnp.array(init_poses)\n",
    "rendered_image = jax3dp3.render_multiobject(init_poses, indices)\n",
    "get_depth_image(rendered_image[:, :, 2], max=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liklihood parameters\n",
    "r = radius = 0.1\n",
    "outlier_prob = 0.01\n",
    "outlier_volume = 1\n",
    "\n",
    "# Enumeration parameters\n",
    "n = 6  # number of enumerated proposals on each dimension (x, y, z).\n",
    "d = 0.05  # the minimum and maximum position delta on each dimension (x, y, z).\n",
    "\n",
    "# Enumerating proposals\n",
    "translation_deltas_global = jax3dp3.make_translation_grid_enumeration(\n",
    "    -d, -d, -d, d, d, d, n, n, n\n",
    ")\n",
    "\n",
    "reward_d = 0.3\n",
    "translation_deltas_reward = jax3dp3.make_translation_grid_enumeration(\n",
    "    -reward_d, -reward_d, -reward_d, reward_d, reward_d, reward_d, n, n, n\n",
    ")\n",
    "\n",
    "\n",
    "def scorer(rendered_image, gt, prior):\n",
    "    weight = jax3dp3.likelihood.threedp3_likelihood(\n",
    "        gt, rendered_image, r, outlier_prob, outlier_volume\n",
    "    )\n",
    "    return prior * weight\n",
    "\n",
    "\n",
    "scorer_parallel = jax.vmap(scorer, in_axes=(0, None, 0))\n",
    "scorer_parallel_jit = jax.jit(scorer_parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Define the liklihood methods and the proposal enumerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liklihood parameters\n",
    "r = radius = 0.1\n",
    "outlier_prob = 0.005\n",
    "outlier_volume = 0.5\n",
    "\n",
    "# Enumeration parameters\n",
    "n = 7  # number of enumerated proposals on each dimension (x, y, z).\n",
    "d = 0.05  # the minimum and maximum position delta on each dimension (x, y, z).\n",
    "\n",
    "# Enumerating proposals\n",
    "translation_deltas_global = jax3dp3.make_translation_grid_enumeration(\n",
    "    -d, -d, -d, d, d, d, n, n, n\n",
    ")\n",
    "\n",
    "reward_d = 0.3\n",
    "translation_deltas_reward = jax3dp3.make_translation_grid_enumeration(\n",
    "    -reward_d, -reward_d, -reward_d, reward_d, reward_d, reward_d, n, n, n\n",
    ")\n",
    "reward_deltas_mask = jnp.abs(translation_deltas_reward[:, -2, -1]) > 1e-6\n",
    "translation_deltas_reward = translation_deltas_reward.at[reward_deltas_mask, -2, -1].set(0)\n",
    "\n",
    "\n",
    "def scorer(rendered_image, gt, prior):\n",
    "    weight = jax3dp3.likelihood.threedp3_likelihood(\n",
    "        gt, rendered_image, r, outlier_prob, outlier_volume\n",
    "    )\n",
    "    return prior * weight\n",
    "\n",
    "\n",
    "scorer_parallel = jax.vmap(scorer, in_axes=(0, None, 0))\n",
    "scorer_parallel_jit = jax.jit(scorer_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_estimates = init_poses.copy()\n",
    "t = start_t\n",
    "gt_image = jnp.array(coord_images[t])\n",
    "\n",
    "translation_deltas = translation_deltas_global\n",
    "translation_deltas_full = jnp.tile(\n",
    "    jnp.eye(4)[None, :, :],\n",
    "    (translation_deltas.shape[0], pose_estimates.shape[0], 1, 1),\n",
    ")\n",
    "translation_deltas_full = translation_deltas_full.at[:, 0, :, :].set(translation_deltas)\n",
    "translation_proposals = jnp.einsum(\n",
    "    \"bij,abjk->abik\", pose_estimates, translation_deltas_full\n",
    ")\n",
    "images = jax3dp3.render_parallel(translation_proposals, 0)\n",
    "prior = jnp.ones((translation_deltas.shape[0],))\n",
    "weights_new = scorer_parallel_jit(images, gt_image, prior)\n",
    "pose_estimates = translation_proposals[jnp.argmax(weights_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:22<00:44,  2.23s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation max which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16025/3483910397.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moccluded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_deltas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mcontaining_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_containment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpose_estimates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcontaining_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mcontainment_relations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontaining_obj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;31m# TODO: extend to list of contained objs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jax3dp3/experiments/cognitive-battery/cog_utils.py\u001b[0m in \u001b[0;36mcheck_containment\u001b[0;34m(pose_estimates, indices, obj_idx, containment_threshold)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mi_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepth_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mi_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepth_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mi_maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mi_mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/jax3dp3/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2753\u001b[0m     \"\"\"\n\u001b[1;32m   2754\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2755\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jax3dp3/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jax3dp3/venv/lib/python3.7/site-packages/jax/_src/numpy/reductions.py\u001b[0m in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m    230\u001b[0m         keepdims=None, initial=None, where=None):\n\u001b[1;32m    231\u001b[0m   return _reduce_max(a, axis=_ensure_optional_axes(axis), out=out,\n\u001b[0;32m--> 232\u001b[0;31m                      keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_argnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'keepdims'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "\u001b[0;32m~/jax3dp3/venv/lib/python3.7/site-packages/jax/_src/numpy/reductions.py\u001b[0m in \u001b[0;36m_reduce_max\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m    224\u001b[0m   return _reduction(a, \"max\", np.max, lax.max, -np.inf, has_identity=False,\n\u001b[1;32m    225\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                     initial=initial, where_=where, parallel_reduce=lax.pmax)\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jax3dp3/venv/lib/python3.7/site-packages/jax/_src/numpy/reductions.py\u001b[0m in \u001b[0;36m_reduction\u001b[0;34m(a, name, np_fun, op, init_val, has_identity, preproc, bool_op, upcast_f16_for_computation, axis, dtype, out, keepdims, initial, where_, parallel_reduce, promote_integers)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater_equal_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"zero-size array to reduction operation {name} which has no identity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0mresult_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation max which has no identity"
     ]
    }
   ],
   "source": [
    "num_steps = num_frames - start_t\n",
    "num_steps = 30\n",
    "inferred_poses = []\n",
    "n_objects = pose_estimates.shape[0]\n",
    "reward_idx = n_objects - 1\n",
    "\n",
    "containment_relations = {}\n",
    "objs_deltas = {}\n",
    "\n",
    "pose_estimates = init_poses.copy()\n",
    "for t in tqdm(range(start_t, start_t + num_steps)):\n",
    "    gt_image = jnp.array(coord_images[t])    \n",
    "    for i in range(n_objects):\n",
    "        if i in set(containment_relations.values()):\n",
    "            continue\n",
    "        translation_deltas = translation_deltas_global if i != reward_idx else translation_deltas_reward\n",
    "        # Check for occlusion\n",
    "        if i == reward_idx:\n",
    "            occluded = utils.check_occlusion(pose_estimates, indices, i)\n",
    "            if occluded:\n",
    "                prior = jnp.ones((translation_deltas.shape[0],))\n",
    "                containing_obj = utils.check_containment(pose_estimates, indices, i)\n",
    "                if containing_obj is not None:\n",
    "                    containment_relations[containing_obj] = i # TODO: extend to list of contained objs\n",
    "                    continue\n",
    "            else:\n",
    "                prior = jnp.ones((translation_deltas.shape[0],))\n",
    "        \n",
    "        pose_estimate = pose_estimates[i]\n",
    "        translation_proposals = jnp.einsum(\"ij,ajk->aik\", pose_estimate, translation_deltas)\n",
    "        # images = jax3dp3.render_parallel(translation_proposals, indices[i])\n",
    "        # images = jax3dp3.render_parallel_multiobject(translation_proposals, indices[i])\n",
    "        weights_new = scorer_parallel_jit(images, gt_image, prior)\n",
    "        best_weight_idx = jnp.argmax(weights_new)\n",
    "        old_pose = pose_estimate.copy()\n",
    "        pose_estimate = translation_proposals[best_weight_idx]\n",
    "        # objs_deltas[i] = translation_deltas[best_weight_idx]\n",
    "        objs_deltas[i] = pose_estimate - old_pose\n",
    "        pose_estimates = pose_estimates.at[i].set(pose_estimate)\n",
    "    \n",
    "    for i, j in containment_relations.items():\n",
    "        new_pose_estimate = pose_estimates[j] + objs_deltas[i]\n",
    "        pose_estimates = pose_estimates.at[j].set(new_pose_estimate)\n",
    "        \n",
    "    inferred_poses.append(pose_estimates.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 12.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output to: swap_out.gif\n"
     ]
    }
   ],
   "source": [
    "all_images = []\n",
    "for t in tqdm(range(start_t, start_t + num_steps)):\n",
    "    rgb_viz = Image.fromarray(rgb_images[t].astype(np.int8), mode=\"RGB\")\n",
    "    gt_depth_1 = get_depth_image(coord_images[t][:, :, 2], max=5.0)\n",
    "    poses = inferred_poses[t - start_t]\n",
    "    rendered_image = jax3dp3.render_multiobject(poses, indices)\n",
    "    rendered_image = get_depth_image(rendered_image[:, :, 2], max=5)\n",
    "\n",
    "    apple_pose = poses[-1]\n",
    "    rendered_apple = jax3dp3.render_single_object(apple_pose, indices[-1])\n",
    "    rendered_apple = [get_depth_image(rendered_apple[:, :, 2], max=5)]\n",
    "    \n",
    "    # rendered_apple = []\n",
    "    # for i in range(len(poses)):\n",
    "    #     render = jax3dp3.render_single_object(poses[i], indices[i])\n",
    "    #     rendered_apple.append(get_depth_image(render[:, :, 2], max=5))\n",
    "    all_images.append(\n",
    "        multi_panel(\n",
    "            [rgb_viz, gt_depth_1, rendered_image, *rendered_apple],\n",
    "            [\n",
    "                f\"\\nRGB Image\",\n",
    "                f\"   Frame: {t}\\nActual Depth\",\n",
    "                \"\\nReconstructed Depth\",\n",
    "                *([\"\\nApple Only\"] * len(rendered_apple)),\n",
    "            ],\n",
    "            # [f\"RGB Image\", f\"Actual Depth\", \"Reconstructed Depth\", \"Reconstructed (Apple Only)\"],\n",
    "            middle_width=10,\n",
    "            label_fontsize=20,\n",
    "        )\n",
    "    )\n",
    "out_path = f\"{scene}_out.gif\"\n",
    "make_gif_from_pil_images(all_images, out_path)\n",
    "print(\"Saved output to:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a3868bdd7d3c8a3e0bdbdcc5d56cecdac1cfc8e4c924f480e3352f5fc391e73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
