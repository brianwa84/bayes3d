{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cognitive Battery Introduction: Jax-3DP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from jax3dp3.viz.img import save_depth_image\n",
    "from jax3dp3.utils import depth_to_coords_in_camera\n",
    "from jax3dp3.transforms_3d import transform_from_pos\n",
    "from jax3dp3.shape import (\n",
    "    get_rectangular_prism_shape,\n",
    ")\n",
    "from jax3dp3.likelihood import threedp3_likelihood\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import jax\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from jax3dp3.rendering import render_planes_multiobject\n",
    "from jax3dp3.enumerations import make_translation_grid_enumeration\n",
    "from jax3dp3.enumerations_procedure import enumerative_inference_single_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize camera metadata and path to data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 103\n",
    "data_path = \"data/videos\"\n",
    "\n",
    "width = 300\n",
    "height = 300\n",
    "fx = 150\n",
    "fy = 150\n",
    "cx = 150\n",
    "cy = 150\n",
    "\n",
    "fx_fy = jnp.array([fx, fy])\n",
    "cx_cy = jnp.array([cx, cy])\n",
    "\n",
    "K = jnp.array(\n",
    "    [\n",
    "        [fx_fy[0], 0.0, cx_cy[0]],\n",
    "        [0.0, fx_fy[1], cx_cy[1]],\n",
    "        [0.0, 0.0, 1.0],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ground-truth RGB images, depth, and segmentation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_images, depth_images, seg_maps = [], [], []\n",
    "rgb_images_pil = []\n",
    "for i in range(num_frames):\n",
    "    rgb_path = os.path.join(data_path, f\"frames/frame_{i}.jpeg\")\n",
    "    rgb_img = Image.open(rgb_path)\n",
    "    rgb_images_pil.append(rgb_img)\n",
    "    rgb_images.append(np.array(rgb_img))\n",
    "\n",
    "    depth_path = os.path.join(data_path, f\"depths/frame_{i}.npy\")\n",
    "    depth_npy = np.load(depth_path)\n",
    "    depth_images.append(depth_npy)\n",
    "\n",
    "    seg_map = np.load(os.path.join(data_path, f\"segmented/frame_{i}.npy\"))\n",
    "    seg_maps.append(seg_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask the depth and segmentation images to only include the relevant part of the scene (i.e. crop to the box above table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_coord_images = []   # depth data in 2d view as images\n",
    "masked_seg_images = []     # segmentation data as images\n",
    "\n",
    "for frame_idx in range(num_frames):\n",
    "    k = 5 if 5 <= frame_idx < 19 else 4  # 4 objects in frames [5:19]\n",
    "\n",
    "    coord_image, _ = depth_to_coords_in_camera(depth_images[frame_idx], K)\n",
    "    segmentation_image = seg_maps[frame_idx]\n",
    "    mask = np.invert(\n",
    "        (coord_image[:, :, 0] < 1.0)\n",
    "        * (coord_image[:, :, 0] > -0.5)\n",
    "        * (coord_image[:, :, 1] < 0.28)\n",
    "        * (coord_image[:, :, 1] > -0.5)\n",
    "        * (coord_image[:, :, 2] < 4.0)\n",
    "        * (coord_image[:, :, 2] > 1.2)\n",
    "    )\n",
    "    coord_image[mask, :] = 0.0 \n",
    "    segmentation_image[mask, :] = 0.0\n",
    "    masked_coord_images.append(coord_image)\n",
    "    masked_seg_images.append(segmentation_image)\n",
    "\n",
    "masked_coord_images = np.stack(masked_coord_images)\n",
    "masked_seg_images = np.stack(masked_seg_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_t = 0\n",
    "\n",
    "coord_image = masked_coord_images[start_t]\n",
    "seg_image = masked_seg_images[start_t]\n",
    "obj_ids = jnp.unique(seg_image[..., 0])\n",
    "\n",
    "shape_planes, shape_dims, init_poses = [], [], []\n",
    "for obj_id in obj_ids:\n",
    "    if obj_id == 0: # Masked background\n",
    "        continue\n",
    "    obj_mask = seg_image[..., 0] == obj_id\n",
    "\n",
    "    masked_coord_image = coord_image * obj_mask[:, :, None]\n",
    "    masked_seg_image = seg_image * obj_mask[:, :, None]\n",
    "\n",
    "    object_points = masked_coord_image[obj_mask]\n",
    "    maxs = np.max(object_points, axis=0)\n",
    "    mins = np.min(object_points, axis=0)\n",
    "    dims = maxs - mins\n",
    "    center_of_box = (maxs + mins) / 2\n",
    "\n",
    "    init_pose = transform_from_pos(center_of_box)\n",
    "    init_poses.append(init_pose)\n",
    "\n",
    "    shape, dim = get_rectangular_prism_shape(dims)\n",
    "    shape_planes.append(shape)\n",
    "    shape_dims.append(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_t = 0\n",
    "\n",
    "coord_image = masked_coord_images[start_t]\n",
    "seg_image = masked_seg_images[start_t]\n",
    "\n",
    "obj_mask = seg_image[..., 0] == 132\n",
    "\n",
    "\n",
    "obj_id = 172\n",
    "obj_mask = seg_image[..., 0] == obj_id\n",
    "\n",
    "masked_coord_image = coord_image * obj_mask[:, :, None]\n",
    "masked_seg_image = seg_image * obj_mask[:, :, None]\n",
    "\n",
    "object_points = masked_coord_image[obj_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a3868bdd7d3c8a3e0bdbdcc5d56cecdac1cfc8e4c924f480e3352f5fc391e73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
